# Optimizing Adaptive Attacks against Content Watermarks for Language Models

<p>
    <a href="https://www.python.org/downloads/">
            <img alt="Build" src="https://img.shields.io/badge/3.12-Python-blue">
    </a>
    <a href="https://pytorch.org">
            <img alt="Build" src="https://img.shields.io/badge/2.6.0-PyTorch-orange">
    </a>
    <a href="https://huggingface.co/">
        <img alt="Hugging Face" src="https://img.shields.io/badge/Hugging%20Face-transformers-yellow">
    </a>
</p>

This repository contains the official code for our paper on adaptive evasion attacks against content watermarks for language models.
Currently, we only release the suite of adaptively tuned paraphrasing models that can be used to test the robustness of your watermark. 

<a href="https://huggingface.co/collections/DDiaa/watermark-removing-paraphrasers-673e3f01fcceafaa2da7e0cf">Pre-trained Adaptively Tuned Paraphrasers<a/>

## Citation

Please consider citing the following paper if you found our work useful.

```
@article{diaa2024optimizing,
  title={Optimizing adaptive attacks against content watermarks for language models},
  author={Diaa, Abdulrahman and Aremu, Toluwani and Lukas, Nils},
  journal={arXiv preprint arXiv:2410.02440},
  year={2024}
}
```
