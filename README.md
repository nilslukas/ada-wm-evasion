# Optimizing Adaptive Attacks against Content Watermarks for Language Models

<p>
    <a href="https://www.python.org/downloads/">
            <img alt="Build" src="https://img.shields.io/badge/3.12-Python-blue">
    </a>
    <a href="https://pytorch.org">
            <img alt="Build" src="https://img.shields.io/badge/2.6.0-PyTorch-orange">
    </a>
    <a href="https://huggingface.co/">
        <img alt="Hugging Face" src="https://img.shields.io/badge/Hugging%20Face-transformers-yellow">
    </a>
</p>

This repository contains the official code for our paper on adaptive evasion attacks against content watermarks for language models.
Currently, we only release the suite of adaptively tuned paraphrasing models that can be used to test the robustness of your watermark. 

<a href="https://huggingface.co/collections/DDiaa/watermark-removing-paraphrasers-673e3f01fcceafaa2da7e0cf">Pre-trained Adaptively Tuned Paraphrasers<a/>

## Citation

Please consider citing the following paper if you found our work useful.

```
@inproceedings{
diaa2025optimizing,
title={Optimizing Adaptive Attacks against Watermarks for Language Models},
author={Abdulrahman Diaa, Toluwani Aremu and Nils Lukas},
booktitle={Forty-second International Conference on Machine Learning},
year={2025},
url={https://openreview.net/forum?id=AsODat0dkE}
}
```
